{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ace902bf",
   "metadata": {},
   "source": [
    "# üß™ Mini Lab: Tool-Enabled Agent + RoPE Extrapolation\n",
    "\n",
    "**Time:** ~1‚Äì2 hours on CPU  \n",
    "**Goals:**\n",
    "- Understand how a minimal **agent loop** drives **tool use** (calculator).\n",
    "- Implement part of the **agent loop** that dispatches tools and records observations.\n",
    "- Understand the core of **Rotary Positional Embeddings (RoPE)** on Q/K.\n",
    "- Observe why **RoPE** outperforms learned absolute positional embeddings on **longer-than-trained** sequences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae26f36a",
   "metadata": {},
   "source": [
    "## Part A ‚Äî A tiny tool‚Äëusing math agent\n",
    "\n",
    "### A1. Background: Why tools? What‚Äôs an ‚Äúagent loop‚Äù?\n",
    "Large Language Models (LLMs) are great at symbolic reasoning in text, but they‚Äôre not exact calculators. A *tool‚Äëusing agent* lets the model **plan ‚Üí act ‚Üí observe ‚Üí continue**: the LLM chooses an action (e.g., *CALCULATE: 17.5 * 1.08*), we execute it with a tool (a safe Python evaluator provided for you), then the LLM uses that result to produce the final answer. This pattern is essential for tasks that require precise operations or external data.\n",
    "\n",
    "Concretely, our agent supports exactly two actions per turn:\n",
    "- `CALCULATE: <arithmetic expression>` ‚Äî run a safe calculator over numbers, `+ - * / ** %`, parentheses, and `round(x, ndigits)`.\n",
    "- `FINAL: <answer>` ‚Äî stop and return the final answer.\n",
    "\n",
    "The agent loop is:\n",
    "1) **Turn 1** (LLM): decide whether to compute ‚Üí either `CALCULATE:` or `FINAL:`.\n",
    "2) If `CALCULATE:`, we evaluate the expression with the calculator tool and pass the **numeric result** back to the LLM.\n",
    "3) **Turn 2+** (LLM): with the result provided, return `FINAL:`. We cap tool uses to keep the loop simple.\n",
    "\n",
    "We‚Äôll compare this agent to a **no-tool baseline** that just asks the LLM to reply with the final number directly. Tool‚Äëuse typically reduces arithmetic slips and rounding drift, especially on multi‚Äëstep word problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc571d55",
   "metadata": {},
   "source": [
    "### A2. Provided starter (API helper, prompts, safe calculator)\n",
    "We provide:\n",
    "- A minimal REST client to call a local LLM endpoint.\n",
    "- A safe arithmetic evaluator (AST whitelist).\n",
    "- Prompts that enforce the `CALCULATE:` / `FINAL:` format.\n",
    "- A small dev set `QUESTIONS` and an evaluation printer.\n",
    "\n",
    "**You do not need to modify the helpers.** Your task is to complete a small missing piece in the agent loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b733aae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PROVIDED: same endpoint helper ---\n",
    "import os, json, textwrap, re, time, ast, operator as op\n",
    "import requests\n",
    "\n",
    "API_KEY  = \"cse476\"\n",
    "API_BASE = \"http://10.4.58.53:41701/v1\"\n",
    "MODEL    = \"bens_model\"\n",
    "\n",
    "def call_model_chat_completions(prompt: str,\n",
    "                                system: str = \"You are a helpful assistant. Reply with only the final answer‚Äîno explanation.\",\n",
    "                                model: str = MODEL,\n",
    "                                temperature: float = 0.0,\n",
    "                                timeout: int = 60) -> dict:\n",
    "    url = f\"{API_BASE}/chat/completions\"\n",
    "    headers = {\"Authorization\": f\"Bearer {API_KEY}\", \"Content-Type\":  \"application/json\"}\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [{\"role\": \"system\", \"content\": system},\n",
    "                     {\"role\": \"user\",   \"content\": prompt}],\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens\": 128,\n",
    "    }\n",
    "    try:\n",
    "        resp = requests.post(url, headers=headers, json=payload, timeout=timeout)\n",
    "        if resp.status_code == 200:\n",
    "            data = resp.json()\n",
    "            text = data.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "            return {\"ok\": True, \"text\": text, \"raw\": data, \"status\": resp.status_code, \"error\": None, \"headers\": dict(resp.headers)}\n",
    "        else:\n",
    "            try: err_text = resp.json()\n",
    "            except Exception: err_text = resp.text\n",
    "            return {\"ok\": False, \"text\": None, \"raw\": None, \"status\": resp.status_code, \"error\": str(err_text), \"headers\": dict(resp.headers)}\n",
    "    except requests.RequestException as e:\n",
    "        return {\"ok\": False, \"text\": None, \"raw\": None, \"status\": -1, \"error\": str(e), \"headers\": {}}\n",
    "\n",
    "# --- PROVIDED: prompts ---\n",
    "SYSTEM_AGENT = \"\"\"You are a math tool-using agent.\n",
    "You may do exactly ONE of the following in your reply:\n",
    "1) CALCULATE: <arithmetic expression>\n",
    "   - use only numbers, + - * / **, parentheses, and round(x, ndigits)\n",
    "   - example: CALCULATE: round((3*2.49)*1.07, 2)\n",
    "2) FINAL: <answer>\n",
    "Return ONE line with the directive and value. No other text.\n",
    "\"\"\"\n",
    "\n",
    "def make_first_prompt(question: str) -> str:\n",
    "    return f\"\"\"Question: {question}\n",
    "If you need arithmetic to get the answer, reply as:\n",
    "CALCULATE: <expression>\n",
    "Otherwise reply:\n",
    "FINAL: <answer>\"\"\"\n",
    "\n",
    "def make_second_prompt(result: str) -> str:\n",
    "    return f\"\"\"The calculation result is: {result}\n",
    "Now provide the final answer.\n",
    "Reply exactly as: FINAL: <answer>\"\"\"\n",
    "\n",
    "\n",
    "ACTION_RE = re.compile(r\"^\\s*(CALCULATE|FINAL)\\s*:\\s*(.+?)\\s*$\", re.IGNORECASE | re.DOTALL)\n",
    "\n",
    "def parse_action(text: str):\n",
    "    \"\"\"\n",
    "    Returns (\"CALCULATE\", expr) or (\"FINAL\", answer); raises ValueError on bad format.\n",
    "    \"\"\"\n",
    "    m = ACTION_RE.match(text.strip())\n",
    "    if not m:\n",
    "        raise ValueError(f\"Unrecognized action format: {text!r}\")\n",
    "    action = m.group(1).upper()\n",
    "    payload = m.group(2).strip()\n",
    "    return action, payload\n",
    "\n",
    "# We provide this function that evaluates arithmetic expressions.\n",
    "ALLOWED_BINOPS = {ast.Add: op.add, ast.Sub: op.sub, ast.Mult: op.mul, ast.Div: op.truediv, ast.Pow: op.pow, ast.Mod: op.mod}\n",
    "ALLOWED_UNOPS  = {ast.UAdd: op.pos, ast.USub: op.neg}\n",
    "\n",
    "def safe_eval(expr: str):\n",
    "    \"\"\"\n",
    "    Evaluates a tiny arithmetic language: numbers, + - * / ** % parentheses, round(x, ndigits).\n",
    "    Converts '^' to '**'. Rejects anything else.\n",
    "    \"\"\"\n",
    "    expr = expr.replace(\"^\", \"**\")\n",
    "    if len(expr) > 200:\n",
    "        raise ValueError(\"Expression too long.\")\n",
    "    node = ast.parse(expr, mode=\"eval\")\n",
    "\n",
    "    def ev(n):\n",
    "        if isinstance(n, ast.Expression):  return ev(n.body)\n",
    "        if isinstance(n, ast.Constant) and isinstance(n.value, (int, float)): return n.value\n",
    "        if isinstance(n, ast.UnaryOp) and type(n.op) in ALLOWED_UNOPS:        return ALLOWED_UNOPS[type(n.op)](ev(n.operand))\n",
    "        if isinstance(n, ast.BinOp) and type(n.op) in ALLOWED_BINOPS:         return ALLOWED_BINOPS[type(n.op)](ev(n.left), ev(n.right))\n",
    "        if isinstance(n, ast.Call) and isinstance(n.func, ast.Name) and n.func.id == \"round\":\n",
    "            args = [ev(a) for a in n.args]\n",
    "            return round(*args)\n",
    "        if isinstance(n, ast.Tuple):  # allow round(x,2) with comma\n",
    "            return tuple(ev(elt) for elt in n.elts)\n",
    "        raise ValueError(f\"Disallowed expression: {ast.dump(n, include_attributes=False)}\")\n",
    "\n",
    "    return ev(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215cb30d",
   "metadata": {},
   "source": [
    "### A3. Task A ‚Äî Implement the second turn of the agent loop (`run_agent`)\n",
    "**Where to edit:** function `run_agent(question: str, max_tool_uses=2, verbose=True)`\n",
    "\n",
    "**Goal:** After you compute `calc_value = safe_eval(payload)`, call the model **again** with the *second prompt* so the model can return `FINAL: ...`. Keep looping while the LLM asks to `CALCULATE:` (capped by `max_tool_uses`).\n",
    "\n",
    "**Step‚Äëby‚Äëstep**\n",
    "1. Call `call_model_chat_completions(system=SYSTEM_AGENT, prompt=make_first_prompt(question))` to get Turn 1. *(Already provided.)*\n",
    "2. Parse the action with `parse_action(...)`. *(Already provided.)*\n",
    "3. **While** action is `\"CALCULATE\"`:\n",
    "   - Evaluate with `safe_eval(payload)` (we‚Äôve done this for you).\n",
    "   - Call the LLM **again** with `make_second_prompt(str(calc_value))`.\n",
    "   - Parse the new action/payload; either loop again or exit when action is `\"FINAL\"`.\n",
    "4. Return the final answer string from `payload`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50af49dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TODO: implement a part of the agent loop ---\n",
    "def run_agent(question: str, max_tool_uses: int = 2, verbose: bool = True):\n",
    "    # Turn 1\n",
    "    # TODO: get the first round response by using the call_model_chat_completions function\n",
    "    # TODO: parse the action and payload from the response\n",
    "    r1 = call_model_chat_completions(prompt=make_first_prompt(question), system=SYSTEM_AGENT, temperature=0.0,)\n",
    "    if not r1[\"ok\"]:\n",
    "        raise RuntimeError(f\"API error: {r1['error']}\")\n",
    "    if verbose: print(\"LLM ‚Üí\", r1[\"text\"])\n",
    "    action, payload = parse_action(r1[\"text\"])\n",
    "\n",
    "    tool_uses = 0\n",
    "    while action == \"CALCULATE\":\n",
    "        if tool_uses >= max_tool_uses:\n",
    "            raise RuntimeError(\"Exceeded tool-use limit.\")\n",
    "        tool_uses += 1\n",
    "\n",
    "        # TODO: run calculator with the payload to get the calculation result\n",
    "        calc_value = calculator(payload)\n",
    "        if verbose: print(\"CALC =\", calc_value)\n",
    "\n",
    "        # TODO: get the second round response by using the call_model_chat_completions function with the second prompt\n",
    "        # Turn 2 (+)\n",
    "        rN = call_model_chat_completions(prompt=make_second_prompt(str(calc_value)), system=SYSTEM_AGENT, temperature=0.0,)\n",
    "        if not rN[\"ok\"]:\n",
    "            raise RuntimeError(f\"API error: {rN['error']}\")\n",
    "        if verbose: print(\"LLM ‚Üí\", rN[\"text\"])\n",
    "\n",
    "        # TODO: parse the action and payload from the response\n",
    "        action, payload = parse_action(rN[\"text\"])\n",
    "\n",
    "    # action must be FINAL here\n",
    "    return payload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a8ae6d",
   "metadata": {},
   "source": [
    "A small test cell below will run both no‚Äëtool and tool‚Äëusing modes side‚Äëby‚Äëside on a dozen questions and print a compact table.\n",
    "\n",
    "(Background reading on agents & tool use from lecture: why and how we ‚Äúact‚Äù between LLM thoughts: See Lecture 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5a1d05f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "API error: HTTPConnectionPool(host='10.4.58.53', port=41701): Max retries exceeded with url: /v1/chat/completions (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000002807F37D520>, 'Connection to 10.4.58.53 timed out. (connect timeout=60)'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 88\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# ---------- Run it ----------\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 88\u001b[0m     evaluate_side_by_side(QUESTIONS, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[4], line 58\u001b[0m, in \u001b[0;36mevaluate_side_by_side\u001b[1;34m(questions, verbose)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mQ\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mq\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# No-tool\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m pred_direct \u001b[38;5;241m=\u001b[39m run_direct(q, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[0;32m     59\u001b[0m ok_direct   \u001b[38;5;241m=\u001b[39m is_correct(pred_direct, gold)\n\u001b[0;32m     60\u001b[0m direct_correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(ok_direct)\n",
      "Cell \u001b[1;32mIn[4], line 23\u001b[0m, in \u001b[0;36mrun_direct\u001b[1;34m(question, verbose)\u001b[0m\n\u001b[0;32m     17\u001b[0m r \u001b[38;5;241m=\u001b[39m call_model_chat_completions(\n\u001b[0;32m     18\u001b[0m     system\u001b[38;5;241m=\u001b[39mSYSTEM_DIRECT,\n\u001b[0;32m     19\u001b[0m     prompt\u001b[38;5;241m=\u001b[39mquestion,\n\u001b[0;32m     20\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m,\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m r[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mok\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLLM(no-tool) ‚Üí\u001b[39m\u001b[38;5;124m\"\u001b[39m, r[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mRuntimeError\u001b[0m: API error: HTTPConnectionPool(host='10.4.58.53', port=41701): Max retries exceeded with url: /v1/chat/completions (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000002807F37D520>, 'Connection to 10.4.58.53 timed out. (connect timeout=60)'))"
     ]
    }
   ],
   "source": [
    "import re, math\n",
    "\n",
    "# ---------- Baseline: no-tool runner ----------\n",
    "SYSTEM_DIRECT = \"You are a careful math assistant. Reply with only the final numeric answer‚Äîno explanation.\"\n",
    "\n",
    "NUM_RE = re.compile(r\"[-+]?\\d+(?:\\.\\d+)?(?:[eE][-+]?\\d+)?\")\n",
    "\n",
    "def extract_number(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Try to normalize model output to a single numeric string.\n",
    "    Falls back to the raw text if no number is found.\n",
    "    \"\"\"\n",
    "    m = NUM_RE.search(text)\n",
    "    return m.group(0) if m else text.strip()\n",
    "\n",
    "def run_direct(question: str, verbose: bool = True) -> str:\n",
    "    r = call_model_chat_completions(\n",
    "        system=SYSTEM_DIRECT,\n",
    "        prompt=question,\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    if not r[\"ok\"]:\n",
    "        raise RuntimeError(f\"API error: {r['error']}\")\n",
    "    if verbose:\n",
    "        print(\"LLM(no-tool) ‚Üí\", r[\"text\"])\n",
    "    return extract_number(r[\"text\"])\n",
    "\n",
    "# ---------- If you need QUESTIONS / is_correct ----------\n",
    "QUESTIONS = [\n",
    "    (\"What is (37 + 58) * 2?\", \"190\"),\n",
    "    (\"A class has 28 students; 25% are absent. How many are present?\", \"21\"),\n",
    "    (\"Solve 3x + 5 = 26 for x.\", \"7\"),\n",
    "    (\"What is 12% of 240?\", \"28.8\"),\n",
    "    (\"Average of 12, 18, 29, 31?\", \"22.5\"),\n",
    "    (\"3 notebooks cost $2.49 each, plus 7% tax. Total to 2 decimals?\", \"7.99\"),\n",
    "    (\"Convert 3.5 hours to minutes.\", \"210\"),\n",
    "    (\"Perimeter of a rectangle 8 by 11.\", \"38\"),\n",
    "    (\"What is 2.5^3?\", \"15.625\"),\n",
    "    (\"Add a 15% tip to $23.80, round to 2 decimals.\", \"27.37\"),\n",
    "]\n",
    "\n",
    "def is_correct(pred: str, gold: str):\n",
    "    try:\n",
    "        return abs(float(pred) - float(gold)) <= 1e-6\n",
    "    except:\n",
    "        return pred.strip() == gold.strip()\n",
    "\n",
    "# ---------- Evaluation harness ----------\n",
    "def evaluate_side_by_side(questions=QUESTIONS, verbose=False):\n",
    "    rows = []\n",
    "    direct_correct = 0\n",
    "    tool_correct   = 0\n",
    "\n",
    "    for i, (q, gold) in enumerate(questions, 1):\n",
    "        if verbose: print(f\"\\nQ{i}: {q}\")\n",
    "\n",
    "        # No-tool\n",
    "        pred_direct = run_direct(q, verbose=verbose)\n",
    "        ok_direct   = is_correct(pred_direct, gold)\n",
    "        direct_correct += int(ok_direct)\n",
    "\n",
    "        # With tool\n",
    "        pred_tool = run_agent(q, verbose=verbose)  # uses your agent loop\n",
    "        ok_tool   = is_correct(pred_tool, gold)\n",
    "        tool_correct += int(ok_tool)\n",
    "\n",
    "        rows.append((i, q, gold, pred_direct, \"‚úì\" if ok_direct else \"‚úó\",\n",
    "                               pred_tool,   \"‚úì\" if ok_tool   else \"‚úó\"))\n",
    "\n",
    "    # Pretty print\n",
    "    print(\"\\n=== Results (No-Tool vs Tool) ===\")\n",
    "    colw = [4, 42, 8, 10, 3, 10, 3]\n",
    "    header = [\"#\", \"Question\", \"Gold\", \"No-Tool\", \"\", \"Tool\", \"\"]\n",
    "    fmt = f\"{{:<{colw[0]}}} {{:<{colw[1]}}} {{:>{colw[2]}}}  {{:>{colw[3]}}} {{:^{colw[4]}}}  {{:>{colw[5]}}} {{:^{colw[6]}}}\"\n",
    "    print(fmt.format(*header))\n",
    "    print(\"-\" * sum(colw) + \"-\"*10)\n",
    "\n",
    "    for r in rows:\n",
    "        i, q, gold, pd, okd, pt, okt = r\n",
    "        q_short = (q[:colw[1]-3] + \"‚Ä¶\") if len(q) > colw[1] else q\n",
    "        print(fmt.format(i, q_short, gold, pd, okd, pt, okt))\n",
    "\n",
    "    print(f\"\\nTotal (No-Tool): {direct_correct}/{len(questions)}\")\n",
    "    print(f\"Total (Tool)   : {tool_correct}/{len(questions)}\")\n",
    "\n",
    "# ---------- Run it ----------\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate_side_by_side(QUESTIONS, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95afd67",
   "metadata": {},
   "source": [
    "### A4. Observe: Tool‚Äëenabled vs. no‚Äëtool inference\n",
    "\n",
    "Run the provided evaluation cell.\n",
    "\n",
    "Report (1‚Äì3 sentences):\n",
    "\n",
    "- In which problems does no‚Äëtool fail but tool succeeds? What‚Äôs common about them (e.g., multi‚Äëstep %, rounding, tax/tip)?\n",
    "\n",
    "- One sentence on why tools help: the calculator provides deterministic, verifiable computations the LLM then conditions on; the direct mode must ‚Äúsimulate‚Äù arithmetic in tokens and can drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23484997",
   "metadata": {},
   "outputs": [],
   "source": [
    "Your_response = \"The no-tool commonly fails on problems that require\" \\\n",
    "\"multiple steps (multi-step %) because it has to both do several \" \\\n",
    "\"operations in sequence and keep track of the decimal places manually. \" \\\n",
    "\"Tools help because it provides deterministic computations, whereas no-tools\" \\\n",
    "\"rely on the model's internal calculation; no matter how large or how long youve\" \\\n",
    "\"trained a model, it will always give non-deterministic results due to the nature\" \\\n",
    "\"of it using probabilistic generation.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125b5bed",
   "metadata": {},
   "source": [
    "## Part B ‚Äî Rotary Positional Embeddings (RoPE)\n",
    "\n",
    "### B1. Background (why RoPE?)\n",
    "Transformers need a way to represent token order. Traditional *absolute* position embeddings (learned tables) do not extrapolate to unseen lengths; *rotary* position embeddings (RoPE) instead rotate each even/odd pair of a vector by a position-dependent angle, so attention depends on **relative** offsets. This often generalizes better beyond the training context length and adds no extra parameters. \n",
    "\n",
    "What you‚Äôll do here:\n",
    "- Implement the first sub-step of a tiny `rope_qk(...)` that rotates **Q** and **K**.\n",
    "- Compare a baseline model with absolute positions vs. a RoPE model on short vs. longer sequences.\n",
    "- Write 2‚Äì4 sentences explaining why RoPE degrades less when the test sequence is longer than training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ceddde",
   "metadata": {},
   "source": [
    "### K-back dataset & LearnedPositionalEncoding\n",
    "\n",
    "**K-back dataset (what & why).** We synthesize sequences of discrete tokens. For each position *t*, the target label is the token that occurred *k* steps earlier:  \n",
    "`y_t = x_{t‚àík}` (for `t > k`; earlier positions are ignored or masked).  \n",
    "This creates a clean, length-agnostic dependency‚Äî‚Äúpoint *k* steps back‚Äù‚Äîthat stresses how a model represents **relative** positions. It‚Äôs simple, controlled, and lets us isolate the effect of positional encoding.\n",
    "\n",
    "**LearnedPositionalEncoding (absolute positions).** This is a standard learned lookup table of shape `[max_len, d_model]`. During training, the model learns a separate embedding vector for each absolute index `0..max_len‚àí1`, which is added to token embeddings. Strength: flexible and effective **within** the trained index range. Limitation: it does not naturally extrapolate to unseen indices; positions beyond what was trained either don‚Äôt exist or are untrained, so performance can drop when sequences get longer.\n",
    "\n",
    "**Protocol in this lab.** We will:\n",
    "1) **Train** both models (Absolute PE baseline and RoPE model) on sequences of a fixed length `L_train`.  \n",
    "2) **Evaluate** on two settings:  \n",
    "   - **In-distribution:** the same length `L_train`.  \n",
    "   - **Out-of-distribution (longer):** a larger length `L_test > L_train`.  \n",
    "This length shift tests positional **extrapolation**: absolute tables tend to degrade at unseen indices, while RoPE‚Äîencoding relative geometry via rotations‚Äîoften maintains accuracy better at longer lengths.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2e585c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Tuple\n",
    "\n",
    "# Torch may already be available on your machine/environment.\n",
    "# If not, uncomment the following line (CPU wheels). If you are offline, skip it and use a local env with torch installed.\n",
    "# !pip install --quiet --index-url https://download.pytorch.org/whl/cpu torch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#@title K-back dataset (predict x[t-k])\n",
    "class KBackDataset(Dataset):\n",
    "    def __init__(self, num_seqs: int, seq_len: int, vocab_size: int, k: int, seed: int = 0):\n",
    "        g = torch.Generator().manual_seed(seed)\n",
    "        self.x = torch.randint(low=0, high=vocab_size, size=(num_seqs, seq_len), generator=g)\n",
    "        self.y = torch.full_like(self.x, fill_value=-100)  # ignore positions < k\n",
    "        self.y[:, k:] = self.x[:, :-k]\n",
    "        self.k = k\n",
    "        self.vocab_size = vocab_size\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __len__(self): return self.x.size(0)\n",
    "    def __getitem__(self, idx): return self.x[idx], self.y[idx]\n",
    "\n",
    "def make_loaders(vocab_size=16, k=3, train_len=64, test_len=128, bs=32):\n",
    "    train_ds = KBackDataset(num_seqs=512, seq_len=train_len, vocab_size=vocab_size, k=k, seed=1)\n",
    "    test_short = KBackDataset(num_seqs=128, seq_len=train_len, vocab_size=vocab_size, k=k, seed=2)   # in-dist\n",
    "    test_long  = KBackDataset(num_seqs=128, seq_len=test_len,  vocab_size=vocab_size, k=k, seed=3)   # OOD (longer)\n",
    "    return (DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
    "            DataLoader(test_short, batch_size=bs),\n",
    "            DataLoader(test_long,  batch_size=bs))\n",
    "\n",
    "# we provide the learned positional encoding \n",
    "class LearnedPositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    Trainable absolute positional embeddings.\n",
    "    \"\"\"\n",
    "    def __init__(self, max_len: int, d_model: int):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(max_len, d_model)\n",
    "\n",
    "    def forward(self, positions: torch.LongTensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          positions: [B, L] integer positions in [0, max_len)\n",
    "        Returns:\n",
    "          pos_emb:  [B, L, d_model]\n",
    "        Example:\n",
    "          >>> pe = LearnedPositionalEncoding(4, 2)\n",
    "          >>> with torch.no_grad():\n",
    "          ...     pe.embedding.weight.copy_(torch.tensor([[1.,2.],[3.,4.],[5.,6.],[7.,8.]]))\n",
    "          >>> pos = torch.tensor([[0,1,3]])\n",
    "          >>> pe(pos).shape\n",
    "          torch.Size([1, 3, 2])\n",
    "        \"\"\"\n",
    "        return self.embedding(positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34496fcb",
   "metadata": {},
   "source": [
    "### B2. Task B ‚Äî Understand the Implementation of `rope_qk(q, k, pos)`\n",
    "\n",
    "Here we have provided the implementation of RoPE - you don't need to change anything.\n",
    "\n",
    "**Notation** \n",
    "- **B** ‚Äî *Batch size*: number of sequences processed together in one step. Example: `B = 32`.\n",
    "- **L** ‚Äî *Sequence length*: number of tokens per sequence. Example: `L = 128`.\n",
    "- **H** ‚Äî *Number of attention heads*. \n",
    "- **D_model** ‚Äî *Model (embedding) dimension*. Token embeddings and residual stream live in `‚Ñù^{D_model}`.\n",
    "- **Dh** ‚Äî *Head dimension* (channels per head). By design `H √ó D_h = D_model`. Example: if `D_model=256` and `H=4`, then `D_h=64`.\n",
    "\n",
    "**Core idea.** Rotary Positional Embeddings (RoPE) attach position information by *rotating* each even/odd pair of channels in a vector by a position-dependent angle. For any head vector `x ‚àà ‚Ñù^{Dh}`, we view it as pairs: `(x‚ÇÄ,x‚ÇÅ), (x‚ÇÇ,x‚ÇÉ), ‚Ä¶`. For position `p` and pair index `i`, we compute an angle `Œ∏(p,i)` and apply a 2D rotation:\n",
    "- new pair = `[x_even, x_odd] ¬∑ [[cos Œ∏, ‚àísin Œ∏],[sin Œ∏, cos Œ∏]]`\n",
    "- i.e., `x_even' = x_even¬∑cos Œ∏ ‚àí x_odd¬∑sin Œ∏`, `x_odd' = x_even¬∑sin Œ∏ + x_odd¬∑cos Œ∏`.\n",
    "\n",
    "**Frequency bands.** Each pair uses a different *frequency* so that low-index pairs rotate slowly and high-index pairs rotate faster. With `Dh` even and `i = 0..(Dh/2‚àí1)`, the per-pair frequency is `freqs[i] = base^{‚àí(2i)/Dh}` (default `base = 10000`). The angle for position `p` is `Œ∏(p,i) = p ¬∑ freqs[i]`.\n",
    "\n",
    "**Why apply to Q and K (not V)?** RoPE rotates **Q** and **K** by the *same* position-dependent angles, so their dot product depends on *relative* positions (phase differences cancel absolute offsets). This preserves attention behavior when sequences get longer than the model saw in training, improving length extrapolation.\n",
    "\n",
    "**Inputs**\n",
    "- `q, k`: `[B, H, L, Dh]` (Dh must be even).\n",
    "- `pos`: `[B, L]` integer positions.\n",
    "- `base`: float (default `10000.0`), controls frequency decay.\n",
    "\n",
    "**Outputs**\n",
    "- `(q_rot, k_rot)`: both `[B, H, L, Dh]`, after applying RoPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b19a7e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_half(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Split last dim into pairs [..., 2*m] -> return [-x2, x1] per pair.\n",
    "    \n",
    "    RoPE rotates each *pair* of channels `(even, odd)` by an angle. `rotate_half(x)` implements a fixed 90¬∞ rotation per pair:\n",
    "    - Split `x[..., : , : , : ]` along the last dimension into even and odd channels.\n",
    "    - Return `[-odd, even]` (i.e., `[x‚ÇÄ, x‚ÇÅ] ‚Üí [-x‚ÇÅ, x‚ÇÄ]`) per pair.\n",
    "    It‚Äôs a helper so that the full rotation matches the 2√ó2 rotation matrix for every `(even, odd)` pair.\n",
    "    \"\"\"\n",
    "    x1, x2 = x[..., ::2], x[..., 1::2]\n",
    "    return torch.stack((-x2, x1), dim=-1).reshape_as(x)\n",
    "\n",
    "def rope_qk(q: torch.Tensor, k: torch.Tensor, pos: torch.LongTensor, base: float = 10000.0) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Apply Rotary Positional Embeddings to Q and K.\n",
    "    Shapes:\n",
    "      q, k: [B, H, L, Dh]  (Dh must be even)\n",
    "      pos:  [B, L] integer positions\n",
    "    Returns:\n",
    "      (q_rot, k_rot) with the same shapes.\n",
    "\n",
    "    RoPE (high-level):\n",
    "      For each position p and each pair of dims (2i, 2i+1), rotate by angle\n",
    "      theta_{p,i} = p / base^{2i/Dh}. This preserves relative positions. :contentReference[oaicite:11]{index=11}\n",
    "    \"\"\"\n",
    "    B, H, L, Dh = q.shape\n",
    "    assert Dh % 2 == 0, \"Dh must be even for RoPE.\"\n",
    "\n",
    "    # 1) Build per-dimension frequencies: [Dh/2]\n",
    "    freqs = 1.0 / (base ** (torch.arange(0, Dh, 2, device=q.device, dtype=q.dtype) / Dh))  # [Dh/2]\n",
    "\n",
    "    # 2) Compute angles for each position: [B, L, Dh/2]\n",
    "    #    Broadcast to [B, 1, L, Dh/2] to align with [B, H, L, Dh]\n",
    "    theta = pos.unsqueeze(-1).to(q.dtype) * freqs  # [B,L,Dh/2]\n",
    "    cos = torch.cos(theta).unsqueeze(1)            # [B,1,L,Dh/2]\n",
    "    sin = torch.sin(theta).unsqueeze(1)            # [B,1,L,Dh/2]\n",
    "\n",
    "    # 3) Interleave cos/sin to match Dh\n",
    "    cos = torch.stack([cos, cos], dim=-1).reshape(B, 1, L, Dh)\n",
    "    sin = torch.stack([sin, sin], dim=-1).reshape(B, 1, L, Dh)\n",
    "\n",
    "    # 4) Rotate: (x * cos) + (rotate_half(x) * sin)\n",
    "    q_rot = q * cos + rotate_half(q) * sin\n",
    "    k_rot = k * cos + rotate_half(k) * sin\n",
    "    return q_rot, k_rot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a5467ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ RoPE rotation passed.\n"
     ]
    }
   ],
   "source": [
    "#@title Tests for TASK B2 (fast and numeric)\n",
    "B,H,L,Dh = 2, 1, 4, 8\n",
    "q = torch.randn(B,H,L,Dh)\n",
    "k = torch.randn(B,H,L,Dh)\n",
    "pos = torch.stack([torch.arange(L), torch.arange(L)], dim=0)  # [B,L] = [[0,1,2,3], [0,1,2,3]]\n",
    "\n",
    "q_rot, k_rot = rope_qk(q, k, pos)\n",
    "assert q_rot.shape == q.shape and k_rot.shape == k.shape\n",
    "\n",
    "# Sanity: at position 0, rotation is identity (theta=0) -> cos=1, sin=0\n",
    "assert torch.allclose(q_rot[:, :, 0], q[:, :, 0], atol=1e-5)\n",
    "assert torch.allclose(k_rot[:, :, 0], k[:, :, 0], atol=1e-5)\n",
    "\n",
    "# Rotation should preserve per-vector 2-norm at each (B,H,L) slice.\n",
    "def norms(x): return torch.linalg.vector_norm(x, dim=-1)\n",
    "assert torch.allclose(norms(q_rot), norms(q), atol=1e-5)\n",
    "assert torch.allclose(norms(k_rot), norms(k), atol=1e-5)\n",
    "print(\"‚úÖ RoPE rotation passed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a5b557",
   "metadata": {},
   "source": [
    "We have provided the implementation of a small transformer LM and a training loop. You don't need to change anything.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "620d42d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Single-layer multi-head self-attention (with optional RoPE)\n",
    "class TinySelfAttention(nn.Module):\n",
    "    def __init__(self, d_model: int, n_heads: int, use_rope: bool):\n",
    "        super().__init__()\n",
    "        assert d_model % n_heads == 0\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.d_head = d_model // n_heads\n",
    "        self.use_rope = use_rope\n",
    "\n",
    "        self.q_proj = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.k_proj = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.v_proj = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.out_proj = nn.Linear(d_model, d_model, bias=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, pos: torch.LongTensor) -> torch.Tensor:\n",
    "        B,L,D = x.shape\n",
    "        H, Dh = self.n_heads, self.d_head\n",
    "\n",
    "        q = self.q_proj(x).view(B, L, H, Dh).transpose(1,2)  # [B,H,L,Dh]\n",
    "        k = self.k_proj(x).view(B, L, H, Dh).transpose(1,2)  # [B,H,L,Dh]\n",
    "        v = self.v_proj(x).view(B, L, H, Dh).transpose(1,2)  # [B,H,L,Dh]\n",
    "\n",
    "        if self.use_rope:\n",
    "            q, k = rope_qk(q, k, pos)  # rotate by RoPE\n",
    "\n",
    "        att = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(Dh)  # [B,H,L,L]\n",
    "        # Full (bidirectional) attention is fine for k-back\n",
    "        w = F.softmax(att, dim=-1)\n",
    "        out = torch.matmul(w, v)  # [B,H,L,Dh]\n",
    "        out = out.transpose(1,2).contiguous().view(B, L, D)\n",
    "        return self.out_proj(out)\n",
    "\n",
    "class TinyTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size: int, d_model: int, n_heads: int,\n",
    "                 max_len: int, use_rope: bool):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_enc = None if use_rope else LearnedPositionalEncoding(max_len, d_model)\n",
    "        self.self_attn = TinySelfAttention(d_model, n_heads, use_rope=use_rope)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, 2*d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2*d_model, d_model)\n",
    "        )\n",
    "        self.lm_head = nn.Linear(d_model, vocab_size)\n",
    "        self.use_rope = use_rope\n",
    "\n",
    "    def forward(self, x: torch.LongTensor):\n",
    "        B, L = x.shape\n",
    "        pos = torch.arange(L, device=x.device).unsqueeze(0).expand(B, L)  # [B,L]\n",
    "        h = self.token_emb(x)\n",
    "        if not self.use_rope:\n",
    "            h = h + self.pos_enc(pos)\n",
    "        h = h + self.self_attn(h, pos)\n",
    "        h = h + self.ffn(h)\n",
    "        return self.lm_head(h)  # [B,L,V]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32d82ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Tuple, Optional, Union, Any, Callable\n",
    "\n",
    "device = torch.device(\"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda\")\n",
    "\n",
    "@dataclass\n",
    "class TrainConfig:\n",
    "    vocab_size: int = 16\n",
    "    k: int = 3\n",
    "    d_model: int = 64\n",
    "    n_heads: int = 4\n",
    "    train_len: int = 64\n",
    "    test_len: int = 128\n",
    "    max_len: int = 256\n",
    "    epochs: int = 2\n",
    "    lr: float = 3e-3\n",
    "    bs: int = 64\n",
    "\n",
    "def accuracy_kback(model: nn.Module, loader: DataLoader, ignore_index: int = -100) -> float:\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            pred = logits.argmax(dim=-1)\n",
    "            mask = (y != ignore_index)\n",
    "            correct += (pred[mask] == y[mask]).sum().item()\n",
    "            total   += mask.sum().item()\n",
    "    return correct / max(1, total)\n",
    "\n",
    "def train_model(use_rope: bool, cfg: TrainConfig) -> Tuple[nn.Module, Dict[str, float]]:\n",
    "    train_loader, test_short, test_long = make_loaders(\n",
    "        vocab_size=cfg.vocab_size, k=cfg.k, train_len=cfg.train_len,\n",
    "        test_len=cfg.test_len, bs=cfg.bs\n",
    "    )\n",
    "    model = TinyTransformer(cfg.vocab_size, cfg.d_model, cfg.n_heads, cfg.max_len, use_rope=use_rope).to(device)\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=cfg.lr)\n",
    "    loss_fn = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "\n",
    "    t0 = time.time()\n",
    "    for epoch in range(cfg.epochs):\n",
    "        model.train()\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            opt.zero_grad()\n",
    "            logits = model(x)      # [B,L,V]\n",
    "            loss = loss_fn(logits.view(-1, cfg.vocab_size), y.view(-1))\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "    t1 = time.time()\n",
    "    acc_train = accuracy_kback(model, train_loader)\n",
    "    acc_short = accuracy_kback(model, test_short)\n",
    "    acc_long  = accuracy_kback(model, test_long)  # longer sequences (OOD for absolute PE)\n",
    "    stats = dict(\n",
    "        sec=round(t1 - t0, 3),\n",
    "        acc_train=acc_train, acc_short=acc_short, acc_long=acc_long\n",
    "    )\n",
    "    return model, stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f9528b",
   "metadata": {},
   "source": [
    "### B3. Run ‚Äî short vs. long sequence evaluation\n",
    "We provide a tiny k-back toy task and two configs:\n",
    "- **Absolute** PE model (learned table).\n",
    "- **RoPE** model (applies `rope_qk` right before attention scores).\n",
    "\n",
    "**What to run**\n",
    "1) Train each model briefly on the *short* length (the in-distribution setting).  \n",
    "2) Evaluate both on the short length (**acc_short**) and on a longer length (**acc_long**) that exceeds the training max.\n",
    "\n",
    "**What to report (2‚Äì4 sentences)**\n",
    "- Compare `acc_short` and `acc_long` for both models.  \n",
    "- Note which one degrades more out of distribution.  \n",
    "- One sentence connecting RoPE‚Äôs relative phase idea to better long-length behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5eda1691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute PE  stats: {'sec': 0.995, 'acc_train': 0.9991355020491803, 'acc_short': 0.9964139344262295, 'acc_long': 0.5259375}\n",
      "RoPE         stats: {'sec': 1.036, 'acc_train': 0.9992635758196722, 'acc_short': 0.9988473360655737, 'acc_long': 0.9666875}\n"
     ]
    }
   ],
   "source": [
    "#@title Run both models (fast, CPU-friendly)\n",
    "cfg = TrainConfig(epochs=10, d_model=64, n_heads=4, train_len=64, test_len=128, bs=64)\n",
    "\n",
    "model_abs, stats_abs = train_model(use_rope=False, cfg=cfg)\n",
    "print(\"Absolute PE  stats:\", stats_abs)\n",
    "\n",
    "model_rope, stats_rope = train_model(use_rope=True, cfg=cfg)\n",
    "print(\"RoPE         stats:\", stats_rope)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7039c75",
   "metadata": {},
   "source": [
    "### B4. Reflection ‚Äî why RoPE holds up better beyond training length\n",
    "Write 2‚Äì3 sentences:\n",
    "- Why absolute position tables struggle on unseen indexes (they simply don‚Äôt have trained vectors for those positions).  \n",
    "- Why RoPE‚Äôs rotation preserves **relative** geometry in Q¬∑K, so behavior extrapolates as sequences get longer.  \n",
    "- Ground with a concrete example (e.g., ‚Äúpredict token k steps back when the sentence is twice as long‚Äù)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962d7cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Your_response = \"Absolute positional embeddings \" \\\n",
    "\"break for indices outside of training range because those have no learned values:\" \\\n",
    "\"this makes attention scores for longer contexts unpredictable. RoPE, on the other hand,\" \\\n",
    "\"encodes the relative positions BETWEEN each token, not their index. So even for sequences \" \\\n",
    "\"longer than the training range, a model is actually able to look k-steps back based on the relative position.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
